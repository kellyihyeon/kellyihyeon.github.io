{"posts":[{"title":"RESTful API - 리소스 이름은 어떻게 지어야할까?","text":"들어가며안녕하세요! 이번 글은 API의 리소스명을 어떻게 지어야하는지에 대한 고민 과정에 대해서 공유하고자 합니다.우선 제가 만들고 있는 서비스에 대해 간략하게 설명드릴게요. 저는 농구 동호회의 어드민 페이지를 만들고 있고 해당 서비스에서 필요한 기능은 크게 두 가지 입니다. 재무 관리 회원 관리 재무 관리 기능은 동호회 모임 통장과 관련한 기능인데요. 가계부 어플을 생각하면 이해하기 쉬울 거예요. 동호회 운영과 관련한 모든 재정적인 활동 내역을 기록하고 조회할 수 있는 기능입니다. 이 글에서는 재무 관리 기능에 대해서만 다룰 거예요.대쉬보드에 이달의 입금 &amp; 지출 내역 Top3 를 보여주고 싶습니다. 해당 API 엔드포인트를 설계하려고 해요. 그런데 리소스 이름을 어떻게 지어야 할까요? 도메인명으로 작성하면 되지 않나?입출금 내역으로 AccountTransaction 이라는 도메인을 사용하고 있어요. 그렇다면 이달의 입금 내역과 지출 내역을 조회하는 API를 설계할 때 /account-transactions 라는 리소스명을 사용하면 되지 않을까요? 아래와 같이 말이죠. 1. 이달의 입금 내역 상위 3개를 조회하는 API HTTP Method: GET Endpoint: /account-transactions/deposits/top3 Query Parameters: year: 조회할 연도 (예: 2024) month: 조회할 월 (예: 7) 2. 이달의 지출 내역 상위 3개를 조회하는 API HTTP Method: GET Endpoint: /account-transactions/expenses/top3 Query Parameters: year: 조회할 연도 (예: 2024) month: 조회할 월 (예: 7) 도메인의 관계가 이렇다면? 모임 통장에서 발생하고 있는 내역을 분류하면 위의 그림과 같아요. 입금 내역 A,B,C와 출금 내역 D,E 라고 설명하겠습니다. 입금 내역 A가 저장이 되면 입출금 내역에 A의 고유 ID와 트랜잭션 타입이 저장됩니다. 입금 내역 A를 조회하고 싶다면 A 테이블을 조회해서 데이터를 가져옵니다. 입출금 내역 테이블에 A의 데이터가 저장되어 있는 게 아니라 테이블의 속성으로 고유 ID와 트랜잭션 타입이 저장되어 있는데 이런 상황에도 /account-transactions 라는 리소스명을 사용해도 되는지 혼란이 왔습니다. API 사용자의 입장에서 생각해볼까?관점을 바꿔서 생각해봅시다. API 엔드포인트의 네이밍은 특정 도메인 객체가 직접적으로 데이터를 포함하고 있는지 여부보다는 리소스의 의미와 API 사용자에게 전달하는 메시지가 중요해요. /account-transactions 를 사용하는 API 사용자의 입장에서 해당 엔드포인트는 어떨까요? 계좌의 거래내역과 관련한 정보를 요청하고 있다 계좌 거래내역이 입금 및 출금과 관련한 메타데이터를 관리하고 있다 계좌 거래 내역의 입금 및 출금 데이터 중 상위 3개의 데이터를 반환한다 2024년, 7월을 파라미터로 전달한다면 2024년 7월 입금 및 출금 데이터 중에서 상위 3개의 데이터를 확인할 수 있다 원하는 결과값을 어느 테이블에서 들고 오느냐는 API 사용자의 관심사가 아닙니다. API 사용자가 원하는 결과값을 어떤 방식으로 구현하느냐는 API 제공자의 역할이에요. API 사용자는 결과값을 요청하는 것이 주된 관심사입니다.따라서 API를 설계할 때는 API 사용자에게 직관적이고 명확한 경험을 제공해주는 것이 중요합니다. 마무리하며API를 만들 때 했던 고민을 글로 정리해 보니 음… 별거 아니게 느껴지네요. 간단하게 결론이 지어졌어요. 사용자의 입장으로 돌아가자! 서비스의 요구사항들이 입출금 내역으로부터 파생되기 때문에 설계를 할 때도 너무 입출금 내역에만 중점을 뒀던 것 같아요.AccountTransaction 도메인은 처음엔 AccountBook 이었다가 AccountLog 가 되기도 했고 필요한 속성들도 수시로 바뀌었습니다. 도메인도 AccountTransaction(입출금 내역), Deposit(입금 내역), Withdrawal(출금 내역) 로 정했다가 계속해서 변경되었어요. 서비스의 요구사항과 목적을 제대로 정립하지 않아서 하나의 도메인이 여러 책임을 담당하게 되고 때문에 도메인의 변경이 잦아졌습니다. 그에따라 API 엔드포인트도 변경을 해야만 했어요. 서비스의 요구사항을 제대로 정립하기 위해선 도메인 탐구가 선행되어야겠다는 판단을 하게 됐습니다. 다음에는 도메인을 탐구하는 과정에서 생긴 일들을 공유하게 되면 좋겠습니다!","link":"/2024/09/04/%EB%A6%AC%EC%86%8C%EC%8A%A4-%EC%9D%B4%EB%A6%84%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EC%A7%80%EC%96%B4%EC%95%BC%ED%95%A0%EA%B9%8C/"},{"title":"GitHub Pages와 Hexo로 기술 블로그 만들기","text":"블로그 시작하기구글링을 하다보면 종종 깃헙 블로그를 보게되는데 뭔가 만들기 어렵고 복잡할 것 같고 이상하게 개발자스러운 느낌이 들었어요. 나도 만들어보고 싶다는 생각’만’ 했었는데 ‘주1회 개발 블로그 작성하기!’ 다짐을 실행하기 위해 깃헙 블로그를 개설합니다. 깃헙 블로그를 사용하려는 이유 도전 정신 - 편의성이 정말 전혀 없어보이지만 그래서 오히려 한번 써보고 싶었어요. 티스토리나 벨로그같은 블로그 시스템은 게시물 등록이라는 행위로 블로그 작성이 끝이나지만, 깃헙 블로그는 하나부터 열까지 다 코드로 작성해야 한다는 얘기를 들어서 경험해보고 싶었어요. 깃헙 잔디 관리 - 기존에는 비쥬얼 스튜디오 코드를 이용해서 md 파일로 TIL를 작성하고 있었어요. 그러다가 팀원들과 공유해야 할 필요성 + 간편함 + 깔끔함을 느끼고 노션으로 갈아탔어요. 이왕 작성하는 TIL와 정보 공유글, 깃헙 블로그로 작성한다면 깃헙에 잔디도 심을 수 있으니 일석이조 아닌가! 라는 생각이 들었어요. 심미성 - 깃헙 + 프레임워크를 사용하면 다양한 테마를 고를 수 있다고 하여 찾아봤더니 마음에 드는 테마를 발견했습니다! 티스토리보다 훨씬 더 다양한 테마가 있어서 블로그를 꾸며보고 싶다는 생각이 들었어요. 꾸준히 작성해보려고 마음 먹은 거 이왕이면 디자인까지 내 마음에 드는 게 있으면 좋잖아요. 블로그 프레임워크정적 사이트를 만들 수 있는 블로그 프레임워크를 찾아보았고 Jekyll 와 Hexo 중에 어떤 걸 사용할지 고민하다가 Hexo 로 결정을 했어요. 두가지 프레임워크는 다음과 같은 특징을 가지고 있습니다. Jekyll 루비 기반 사용자가 가장 많음 테마가 다양함 Hexo 자바스크립트(Node js) 기반 문서화가 잘 되어 있음 테마가 다양함 깃헙 블로그로 구글링을 하면 깃헙 블로그 + Jekyll 조합이 많은데 저는 자바스크립트 기반의 Hexo 로 선택을 했어요. 루비에 대해서 전혀 모르기도 하고 회사에서 Node js 를 배울 기회가 있을 것 같아서 블로그 작성하면서 미리 찍먹해보려고요. Hexo 에서 제공해주는 테마를 구경하다가 마음에 드는 테마를 발견했어요. 테마 이름은 Matery 입니다. Matery 테마를 어떻게 내 블로그에 적용하고 배포하는지 알아보도록 합시다. Hexo 로 깃헙에 배포까지!Hexo 가 뭔가요?Documentation Hexo는 빠르고 간단하고 강력한 블로그 프레임워크예요. 마크다운이나 다른 마크업 언어로 게시글을 작성하면 Hexo 는 몇초만에 정적파일을 생성해줍니다. Hexo 설치하기Hexo를 설치하기 이전에 필요한 요구사항 Hexo를 설치하는 방법은 아주 쉽고 간단합니다. 아래와 같은 2가지 사항만 준비하면 돼요. 12﹒Node.js (최소한 Node.js 10.13 버전이 필요하고, 12.0 버전 이상을 추천합니다.)﹒Git Node.js 와 Git 이 이미 설치가 되어 있다면 바로 Hexo 설치하기 단계로 가시면 됩니다. (Git 설치는 생략하도록 하겠습니다.) Node.js 설치하기 Homebrew를 이용해서 Node.js를 설치합니다. node 설치가 성공적으로 끝났다면 아래의 명령어를 이용해서 node 버전을 확인해봅니다. 12$ brew install node$ npm -version Hexo 설치하기 모든 요구사항을 설치했다면 이제 npm 으로 Hexo를 설치할 수가 있습니다. 1$ npm install -g hexo-cli Hexo 초기화Hexo 가 설치 됐다면, 다음 명령어를 실행해서 에서 Hexo를 초기화해봅시다! 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 저는 디렉토리명을 ‘blog’로 해서 생성했어요. blog 디렉토리로 이동을 해서 리스트를 살펴보겠습니다. 1234$ ~/workspace ▶️ hexo init blog$ ~/workspace ▶️ cd blog$ ~/workspace/blog ▶️ ll$ ~/workspace/blog ▶️ npm install Hexo를 초기화 하고 나면, 프로젝트 폴더는 아래와 같은 구조로 되어있을 거예요. 제 blog 디렉토리 구조를 보시죠. 12345678_config.landscape.yml_config.ymlnode_modulespackage-lock.jsonpackage.jsonscaffoldssourcethemes _config.yml 수정_config.yml 은 사이트 환경설정 파일이에요. 우리는 여기에서 블로그에 대한 대부분의 세팅을 설정 할 수가 있어요. 몇가지 블로그 세팅을 한번 해볼게요! 환경설정 문서: https://hexo.io/docs/configuration 참고로 문서를 편집하기 위한 명령어는 아래와 같아요. vim 을 이용해서 yml 파일을 열어볼게요. 1$ blog ▶️ vim _config.yml Site내 블로그의 타이틀과 서브타이틀, 설명, 작성자를 수정해봅시다. 12345678# Sitetitle: 지식 보관소subtitle: '주요활동: 자료 수집 및 정돈'description: '필요할 때 꺼내쓰기 위해 잘 정리된 자료를 보관하는 곳'keywords:author: mynamelanguage: entimezone: '' URLURL 도 수정해보겠습니다. url 에는 내 깃헙 블로그 주소를 입력해주면 돼요. 1234567# URLurl: https://my_github_username.github.io/permalink: :year/:month/:day/:title/permalink_defaults:pretty_urls: trailing_index: true # Set to false to remove trailing 'index.html' from permalinks trailing_html: true # Set to false to remove trailing '.html' from permalinks 먼저 url 부분을 보면 내 깃헙 블로그 주소를 적어야 하는데 우선 username.github.io 라는 이름으로 깃헙 레포지토리를 생성해야 해요. (usrname 은 GitHub 계정의 username을 의미합니다.) 레포지토리 생성 후 해당 레포지토리의 주소를 url 부분에 적어주세요. DeploymentOne-command deployment해당 가이드는 https://hexo.io/docs/one-command-deployment 에서 가져온 내용이에요. Hexo는 빠르고 쉬운 배포 전략을 제공하고 있는데요, 내 블로그를 서버에 배포하려면 하나의 명령어만 입력하면 끝입니다. 1$ ~/workspace/blog ▶️ hexo deploy _config.yml 파일에 deploy 부분을 찾아서 실행시켜주는 명령어예요. 그러려면 deploy 부분이 먼저 정의되어 있어야겠죠. _config.yml 파일을 통해서 배포 설정을 할 수가 있습니다. 배포 구성요소에는 type 필드가 반드시 있어야 해요. 여러개의 배포 플러그인을 사용할 수도 있는데요 아래와 같이 type을 작성해주면 Hexo는 작성된 순서대로 플러그인을 실행시켜 줄 거예요. 12345deploy:- type: git repo:- type: heroku repo: GitGit 배포 플러그인을 사용하는 방법을 소개하겠습니다. hexo-deployer-git 을 설치해주세요. 1$ ~/workspace/blog ▶️ npm install hexo-deployer-git --save _config.yml 파일을 아래와 같이 수정해 봅시다. 12345deploy: type: git repo: &lt;repository url&gt; # https://bitbucket.org/JohnSmith/johnsmith.bitbucket.io branch: [branch] message: [message] 예시를 살펴볼까요? Hexo 에서 배포할 때 어떤 레포지토리와 브랜치에 배포를 할 것인지를 설정해주었어요. $ hexo deploy 명령어를 실행하면 해당 레포지토리의 브랜치로 푸쉬가 됩니다. 1234deploy: type: git repo: https://github.com/username/username.github.io branch: main deploy 하기 위한 명령어를 입력해줍니다 12$ ~/workspace/blog ▶️ hexo clean$ ~/workspace/blog ▶️ hexo deploy 설정한 깃헙 레포지토리의 ‘Settings’ → ‘Pages’ 탭을 확인해봅니다. Branch 부분이 gh-pages로 되어있는지 확인하고, 그렇지 않다면 변경해줍니다. 블로그가 잘 만들어졌는지 웹페이지를 확인해봐야겠죠? username.github.io 로 접속해 확인해봅시다! 마치며 새로운 게시글을 등록하려면 매번 hexo clean → hexo deploy 명령어를 입력해야 합니다. GitHub Actions 를 사용해 배포 과정을 자동화할 수 있는 방법이 공식문서에 소개되어 있는데, 따라 만들어보면 좋을 것 같아요. main 브랜치와 gh-pages 브랜치를 나눠서 관리하는 방법으로 만들어보려다 처참히 실패하였습니다. gh-pages 브랜치에서 게시글 이력 관리를 할 수 있게끔 하고 main 브랜치에 수정 부분을 반영해서 관리하는 것 같은데, 이 부분은 추후에 다시 해보고 어떻게 고쳤는지 작성해보겠습니다. 튜토리얼을 보고 블로그를 만드는 데까지는 시간이 얼마 안걸렸지만 블로그 글로 정리 해보려고 하니 헷갈리는 부분이 많아 구글링 해보고 프로젝트 날렸다가 다시 만들어보고 하다보니 시간이….상당히 많이 걸리네요 ㅠㅠ….","link":"/2023/10/15/GitHub-Pages%EC%99%80-Hexo%EB%A1%9C-%EA%B8%B0%EC%88%A0-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0/"},{"title":"order_by_후_group_by_를_하고_싶을_때","text":"단순 쿼리 해결 방법을 글로 남기는 이유group by 내부 정렬하는 방법을 구글링 한 게 이번이 처음이 아니기 때문입니다. 몇달 전에도 같은 문제로 구글링을 했고 동일한 해결 과정을 거쳤었어요. 구글링하면서 “아, 맞다! 맞다. 맞다. 아 이거 안되지 참….” 을 반복하면서 이건 정리를 하면서 공부해 놓고 넘어가야 다음에 또 반복 안하겠다는 생각이 들었습니다. 그동안 빨리 쿼리 짜서 원하는 데이터가 결과로 나오는 걸 확인하고 다음 스텝으로 넘어 갔었는데 시간 없다는 핑계로 계속 다음 다음만 했다가는 계속 이런 식으로만 개발할 것 같아서 잘 모르고 넘어갔던 빈틈을 채워보려고 합니다. 하고 싶은 것배치 로직을 개발해야 하는데 이에 필요한 데이터를 쿼리문으로 들고 와야해요. 필요한 데이터는 ‘보험 아이디 별 최신 데이터 한 건’ 입니다. 회사 데이터를 가져올 수가 없어서 제가 하고 싶은 쿼리를 뽑아낼 수 있는 샘플 데이터를 가지고 왔어요. 해당 케이스에서의 미션은 아래와 같습니다. ⭐️ 미션: product_code(상품코드)별 제일 최근에 등록된 데이터 가져오기 원하는 결과 샘플 데이터가 조금 고르지 못한데요. 미션을 성공하려면 id 가 1, 2, 3, 11, 7, 8, 9, 13, 14 번 데이터가 나와야해요. 나머지 데이터는 뒤로하고, 여기서 주의 깊게 봐야할 데이터는 product_code 가 406인 데이터와 378인 데이터입니다. 상품코드 406번의 로그를 보면 ‘상품 등록 → 수정 → 수정 → 수정’ 으로 제일 최근 데이터는 id 가 11번인 데이터 입니다. 상품코드 378번은 id가 13번인 데이터가 나와야 하구요. 왜… 왜 이렇게 나오는데…product_code 별로 created_at 을 최신순 정렬을 한 다음에 해당 데이터 row만 뽑으면 내가 원하는 결과를 가져올 수 있겠다 생각하고 쿼리를 짭니다. 쿼리는 아래와 같습니다. 1234SELECT id, product_code, log_value, created_at FROM product_sale_logGROUP BY product_codeORDER BY created_at DESC; 쿼리의 결과를 살펴볼까요? created_at 을 보면 데이터가 최신순으로 정렬되어 있는 것처럼 보이지만 제가 의도한 결과는 아닙니다. 전체 데이터를 최신순으로 정렬하는 게 아니라 일단 데이터를 product_code 별로 묶고, product_code 내에서 최신순으로 정렬한 결과 가장 최근의 데이터 행 하나를 원했던 것이었어요. GROUP BY는 된듯한데 GROUP BY 내에서 정렬은 일어나지 않은 것 같아요. 위의 결과는 product_code 별로 묶을 때 데이터베이스에 저장되어 있는대로 첫번째 row를 기준으로 묶어서 가져온 것이에요. 왜….? 왜 ORDER BY 는 싸그리 무시된 채 GROUP BY 만 적용이 된 걸까요…. query 가 실행되는 순서를 살펴봅시다. 해당 query 를 실행시키면 product_code 를 기준으로 GROUP BY 를 해요. 이 때 이미 각 product_code 별로 첫번째 행을 가져왔어요. 데이터 행에서 id, product_code, log_value, created_at 컬럼을 가져오고, 이렇게 구성된 데이터를 created_at 을 기준으로 ORDER BY 합니다. 그래서 데이터가 저렇게 나온 거죠. 작성한 쿼리대로 데이터는 잘 나왔어요. 1💡 쿼리가 실행되는 순서: **GROUP BY** -&gt; **ORDER BY** group by 내부 정렬하기왜 결과가 의도한 대로 나오지 않았는지 알았으니, 이제 원하는 결과를 뽑을 수 있는 쿼리를 짜보도록 합시다. 미션을 다시 떠올려보아요. ‘product_code(상품코드)별 제일 최근에 등록된 데이터 가져오기’ group by → order by 순으로 실행이 되니까 그럼… group by 하기 전에 created_at 컬럼을 최신순으로 order by를 해놓고 이렇게 정렬된 데이터를 대상으로 product_code 로 group by를 하면 원하는 결과가 나오지 않을까요? 쿼리문으로 한번 옮겨볼게요. 123SELECT id, product_code, log_value, created_at FROM (select * from product_sale_log order by created_at desc) as subGROUP BY product_code; 378번 상품코드와 406번 상품코드의 로그는 ‘상품 등록‘ 이에요. 네… 잘못되었습니다. 원하는 결과가 아니에요. FROM 절의 (select * from product_sale_log order by created_at desc) 해당 쿼리를 따로 뜯어서 실행시킨 것과 서브 쿼리 내에서 실행결과가 달라요. MySQL은 ORDER BY 가 서브쿼리 안에 있을 때 성능 이슈 문제 때문에 ORDER BY가 무시된다고 합니다. Rank() 와 Partition By() 사용하기반드시 GROUP BY 를 써서 해결을 해야할 필요가 없었기 때문에 다른 방법을 사용해서 해결하려고 합니다. 순위를 매기는 rank() 함수를 이용해서 product_code 별로 최신순으로 랭킹을 세우고, 랭킹이 1번인 데이터 행을 가져오게 하면 의도한 결과를 낼 수 있을 것 같아요. 해당 쿼리는 아래와 같습니다. 123456789SELECT id, product_code, log_value, created_atFROM ( select id, product_code, log_value, created_at, rank() over (partition by product_code order by created_at desc ) rank from product_sale_log ) testwhere rank = 1order by created_at desc; 상품코드 378번과 406번의 데이터를 보면 드디어 의도한 결과가 나온 것을 확인할 수 있습니다. select 에 rank 데이터도 확인해보면 랭킹이 1인 데이터를 가져온 것을 확인해볼 수가 있어요. 공부해봐야할 점 Order By 가 서브쿼리에 존재할 때 어떤 성능 이슈가 있는지 w3schools 에서 OrderDetails 테이블을 대상으로 쿼리 테스트를 했을 때는 서브쿼리에 order by 를 적용해서 만든 아래의 쿼리가 잘 적용이 되었어요. 왜 된 건지 그리고 지금 사용하고 있는 db 툴에서는 왜 안되는 건지. 어떨 때 되고 안되는지를 더 알아봐야 될 것 같습니다.","link":"/2023/10/30/order-by-%ED%9B%84-group-by-%EB%A5%BC-%ED%95%98%EA%B3%A0-%EC%8B%B6%EC%9D%84-%EB%95%8C/"},{"title":"OpenAPI Generator로 페이징 처리는 어떻게 해? (with Spring)","text":"들어가며안녕하세요! 이번 글은 스프링에서 OpenAPI Generator 로 페이징 처리 하는 과정에 대해서 공유하려고 합니다. 이번에도 제가 만들고 있는 서비스를 먼저 소개해야겠죠? 저는 농구 동호회의 어드민 페이지를 만들고 있어요. 해당 서비스에서 필요한 기능은 크게 두 가지 입니다. 재무 관리 회원 관리 재무 관리 기능은 동호회 모임 통장과 관련한 기능인데요. 가계부 어플을 생각하면 이해하기 쉬울 거예요. 동호회 운영과 관련한 모든 재정적인 활동 내역을 기록하고 조회할 수 있는 기능입니다. 이 글에서는 재무 관리 기능에 대해서만 다룰 거예요. 모임 통장의 모든 입출금 내역을 조회하는 API 가 있습니다. 입출금 내역은 시간이 갈수록 쌓이기 때문에 데이터가 굉장히 많은데요. 그래서 해당 API 를 페이징 처리 하려고 합니다. 그런데 OpenAPI Generator 로는 어떻게 페이징 처리를 해야할까요? 페이징 처리를 하고 싶어Controller 계층에서 메서드를 직접 정의하는 경우에는 일반적으로 아래와 같이 처리해요. 파라미터의 Pageable 객체가 보이시나요? Pageable 을 이용해서 페이지네이션 처리를 하게 됩니다. 해당 API 로 요청을 해볼까요? /transactions?page=0&amp;size=10 로 요청을 하면 첫 페이지의 데이터 10개를 반환합니다. 12345678910111213@RestController@RequiredArgsConstructor@RequestMapping(&quot;/transactions&quot;)public class TransactionController { private final TransactionService transactionService; @GetMapping public Page&lt;Transaction&gt; getTransactions(@PageableDefault(size = 10) Pageable pageable) { return transactionService.getTransactions(pageable); }} OpenAPI Generator로는 어떻게 해?OpenAPI Generator는 openapi.yaml 파일에 정의된 스펙을 읽고 코드를 만들어줍니다. 그렇기 때문에 OpenAPI 스펙에서 페이지네이션을 정의하는 방식을 사용해야 해요. 방법 1: API에 정의된 클래스 대신 Spring 클래스를 사용하도록 만들기우선 OpenAPI에 스펙을 정의해야 해요. 파라미터의 스키마를 정의하는 곳에 Pageable 객체를 참조하도록 작성합니다. 하지만 우리가 정의해놓은 Pageable 객체를 사용하진 않을 거예요. Spring에서 제공하는 Pageable 객체를 사용하게 할 건데요. 1. openapi.yaml 에 스펙 정의하기12345678910111213141516171819paths: /transactions: get: parameters: - in: query name: pageable required: false schema: $ref: '#/components/schemas/Pageable'components: schemas: Pageable: description: minimal Pageable query parameters type: object properties: page: type: integer size: type: integer 2. build.gradle 에 매핑 추가하기123456openApiGenerate { ... importMappings = [ 'Pageable': 'org.springframework.data.domain.Pageable' ]} gradle 파일에 해당 코드를 추가해주면 API에 정의된 Pageable 클래스 대신 Spring의 Pageable 객체를 import 해올 거예요. OpenAPI를 구현한 controller 계층123456789@RestController@RequiredArgsConstructorpublic class TransactionController implements TransactionApi { @Override public ResponseEntity&lt;List&lt;TransactionResponse&gt;&gt; getAllTransactions(Pageable pageable) { return null; }} 문제점우리가 정의해놓은 Pageable 객체가 아닌 Spring의 Pageable 객체를 사용하기 위해서는 어쨌든 openapi.yaml 파일에 Pageable 객체를 작성해야 한다는 점입니다. OpenAPI 생성기가 사용하지도 않을 클래스를 생성해야 한다는 것이죠. 방법 2: OpenAPI Generator가 지원하는 확장 플래그 사용하기OpenAPI Generator 공식문서 를 확인해보면 스프링에서 사용할 수 있는 VENDOR EXTENSIONS 를 확인해볼 수 있어요. 페이징처리와 관련 있는 확장 플래그는 아래와 같아요. Default Value 가 false로 설정이 되어있는데 이걸 true로 설정해주면 되는 거죠. 1. openapi.yaml 에 확장 플래그 추가하기12345678paths: /transactions: get: tags: - transaction summary: 입출금 내역을 조회합니다. operationId: getAllTransactions x-spring-paginated: true 2. build.gradle 에 springdoc-openapi 의존성 추가하기1234dependencies { // springdoc-openapi implementation 'org.springdoc:springdoc-openapi-ui:1.8.0'} build.gradle 파일에 springdoc-openapi 관련 의존성을 추가해야 해요. 최신 버전을 사용 중인지도 확인해야 합니다. springdoc-openapi 가 왜 필요할까?springdoc-openapi 는 Spring 애플리케이션에서 OpenAPI와 관련된 기능을 처리하는 라이브러리예요. 해당 의존성을 추가하는 이유는 OpenAPI와 Spring 간의 통합을 처리하기 위해서입니다. Pageable 같은 Spring의 복잡한 객체를 OpenAPI 스펙으로 변환하고 이를 적절히 문서화하기 위해 필요해요. x-spring-paginated: true OpenAPI Generator가 자동으로 Pageable 객체를 생성하는 역할을 합니다. ParameterObject 애노테이션 OpenAPI 생성기가 자동 생성해준 인터페이스를 열어봅시다. 아래와 같은 @ParameterObject 애노테이션을 확인해볼 수 있어요. 123456public interface TransactionApi { ResponseEntity&lt;List&lt;TransactionResponse&gt;&gt; getAllTransactions( @ParameterObject final Pageable pageable );} OpenAPI에서 Pageable 과 같은 복잡한 객체를 처리하려면 @ParameterObject 애노테이션을 사용하여 해당 객체를 명확하게 정의해줘야 합니다. @ParameterObject 애노테이션은 springdoc-openapi 라이브러리에서 제공하고 있고, 해당 라이브러리를 추가하지 않으면 파라미터 매핑에 실패하게 돼요. 문제점springdoc-openapi 의존성을 추가해야 Pageable 같은 복잡한 객체를 처리할 수 있다는 것입니다. 프로젝트 복잡성 증가 페이징 처리와 관련하여 추가적으로 의존성을 관리해야 합니다. 라이브러리 버전 호환성 문제를 발생시킬 가능성이 높습니다. 빌드 시간 증가 의존성이 추가될 수록 빌드 시간이 늘어나고, 전체 프로젝트의 크기가 증가될 수 있습니다. 외부 라이브러리에 대한 의존성 라이브러리의 업데이트 상황에 따라 문제가 발생할 수 있으므로 프로젝트가 외부 라이브러리에 의존하게 됩니다. 방법 3: Pageable 관련 파라미터 직접 정의하기OpenAPI 스펙에서 page ,siz 파라미터를 직접 정의하고 컨트롤러 계층에서 수동으로 Pageable 객체를 생성하는 방법입니다. 이 방식을 사용하면 springdoc-openapi 라이브러리에 의존하지 않으면서 페이징 기능을 사용할 수 있어요! 1. openapi.yaml 에 파라미터 정의하기123456789101112131415161718192021222324paths: /transactions: get: parameters: - in: query name: page schema: type: integer default: 1 - in: query name: size schema: type: integer default: 10 responses: '200': description: A paged list of transactions content: application/json: schema: type: array items: $ref: '#/components/schemas/TransactionResponse' 2. 컨트롤러 계층에서 페이지네이션 처리하기123456789101112@RestController@RequiredArgsConstructorpublic class TransactionController implements TransactionApi { @Override public ResponseEntity&lt;List&lt;TransactionResponse&gt;&gt; getAllTransactions(Integer page, Integer size) { PageRequest pageable = PageRequest.of(page, size); System.out.println(&quot;pageable = &quot; + pageable); return ResponseEntity.ok(null); }} page, size 파라미터를 전달하지 않고 API 요청을 하면 결과는 아래와 같습니다. http://localhost:8080/transactions pageable = Page request [number: 1, size 10, sort: UNSORTED] page와 size 파라미터를 전달하여 API 요청을 해보겠습니다. http://localhost:8080/transactions?page=2&amp;size=10 pageable = Page request [number: 2, size 10, sort: UNSORTED] 문제점 컨트롤러 계층에서 Page 객체를 직접 생성해줘야 합니다. page와 size 파라미터에 대한 유효성 검사를 별도로 해야 한다는 점입니다.예를 들면 page와 size 값이 음수일 경우에 대한 처리가 필요해요. 이런 페이지네이션 파라미터에 대한 유효성 검사는 코드에서 별도로 처리해야 해요. 응답에 페이지네이션 정보가 없는데?12345678910@RestController@RequiredArgsConstructorpublic class TransactionController implements TransactionApi { @Override public ResponseEntity&lt;List&lt;TransactionResponse&gt;&gt; getAllTransactions(...) { // ... return ResponseEntity.ok(null); }} 위에서 제시한 세 가지 방법 중 어떤 방법을 쓰더라도 OpenAPI Generator 가 생성해주는 응답값은 위 코드와 같습니다. List&lt;TransactionResponse&gt; List 타입을 반환해주죠. OpenAPI 에서는 Page 객체를 직접적으로 처리하거나 반환하는 것이 불가능해요. 원하는 데이터를 페이징 처리해서 들고와도 컨트롤러는 여전히 List만 반환해줄 뿐입니다… 😭 이 문제를 해결하기 위한 방법은 페이징 관련 정보를 별도로 제공해주는 것입니다! 컨텐츠와 페이징 메타데이터를 포함하는 응답 객체를 만들어서 클라이언트에 전달해주는 방법을 사용해볼 거예요. 1. 페이징 메타데이터 구성하기아래 그림은 /transactions API 를 호출했을 때 보여주고 싶은 화면이에요. 여기에 페이징 처리를 해볼 건데요. 클라이언트에 어떤 페이징 정보를 전달해야할까요? 클라이언트는 전달받은 페이징 정보를 기반으로 페이징 UI를 구성합니다. 1. pageNumber (현재 페이지 번호) 현재 보고 있는 페이지가 몇 번째인지 명확히 알려줄 수 있어요. 예를 들면 pageNumber = 3일 때 “3 of 10” 과 같은 정보를 표시해줄 수 있어요. 2. itemsPerPage (페이지 당 데이터 개수) 한 페이지에 몇 개의 데이터가 표시되는지 알 수 있습니다. 사용자가 한 페이지에서 보고 싶은 데이터 개수를 조정할 수 있어요. 예를 들면, “30개씩 보기” 버튼을 통해 한번에 보고 싶은 데이터의 개수를 조정할 수 있어요. 3. totalElements (전체 데이터 개수) 전체 데이터 개수를 알 수 있습니다. 전체 데이터 양을 통해 더 많은 데이터가 있는지 혹은 얼마나 남았는지를 파악할 수 있어요. 예를 들면, “총 150개의 항목 중 30개를 표시하고 있어요.” 와 같은 정보를 알려줄 수 있어요. 무한 스크롤을 구현할 때 유용하게 쓰여요! 4. totalPages (전체 페이지 수) 전체 페이지 수를 알 수 있습니다. totalPages = 10 이라면 페이지 이동을 위한 UI를 제공할 수 있어요. totalPages 데이터를 기반으로 “다음” 버튼을 활성화 할지 비활성화 할지 등의 동작을 결정할 수 있어요. 2. 페이징 메타데이터를 공통 스키마로 정의하기123456789101112131415161718components: schemas: PagingMetadata: type: object properties: pageNumber: type: integer itemsPerPage: type: integer totalElements: type: integer totalPages: type: integer required: - pageNumber - itemsPerPage - totalElements - totalPages openapi.yaml 에 PagingMetadata 를 공통 스키마로 정의했어요. 페이징 데이터가 필요한 다른 API 에서도 PagingMetadata 를 사용할 수 있게 하려고요. 3. OpenAPI 응답값 수정하기12345678910111213141516171819202122paths: /transactions: get: parameters: - in: query name: page schema: type: integer default: 1 - in: query name: size schema: type: integer default: 10 responses: '200': description: successful operation content: application/json: schema: $ref: '#/components/schemas/PagedTransactionResponse' /transactions API를 호출하면 ResponseEntity&lt;PagedTransactionResponse&gt; 객체를 응답하게 만들었어요. 이렇게 만든 이유는 PagedTransactionResponse 응답 객체를 아래와 같이 구성하고 싶어서예요! 123456public class PagedTransactionResponse { List&lt;TransactionResponse&gt; content; PagingMetadata paging;} 4. openapi.yaml 에 PagedTransactionResponse 스키마 추가하기1234567891011121314components: schemas: PagedTransactionResponse: type: object properties: content: type: array items: $ref: '#/components/schemas/TransactionResponse' paging: $ref: '#/components/schemas/PagingMetadata' required: - content - paging 5. 해당 컨트롤러 확인하기123456789101112@RestController@RequiredArgsConstructorpublic class TransactionController implements TransactionApi { @Override public ResponseEntity&lt;PagedTransactionResponse&gt; getAllTransactions(Integer page, Integer size) { PageRequest pageable = PageRequest.of(page, size); System.out.println(&quot;pageable = &quot; + pageable); return ResponseEntity.ok(null); }} 짠 😎 OpenAPI Generator 가 페이징 메타정보가 포함된 응답값을 자동으로 생성해주는 것을 확인할 수가 있습니다! 마무리하며OpenAPI Generator 로 페이징 처리 하는 방법을 찾아보는 데 생각보다 시간이 많이 걸렸어요. ㅠ_ㅜ… 세 가지 방법 중 springdoc-openapi 의존성을 추가해서 Pageable 객체를 처리하는 방식을 선택하면 관리 포인트가 늘어난다는 점에서 해당 방법은 고려하지 않았어요. 라이브러리 버전에 따라 프로젝트가 실행이 안될 가능성이 높고 외부 라이브러리에 대한 의존성이 강하게 결합되어 있다고 판단했습니다. 저는 OpenaAPI 스펙에 Pageable 관련 파라미터를 직접 정의하는 방법을 선택했습니다. 현재 프로젝트에 페이징 처리가 필요한 API 가 많이 없기 때문에 필요한 파라미터를 직접 정의하는 방식이 적절할 것 같았어요. 페이징 처리를 해야 하는 API가 많아진다면 Pageable 관련 파라미터와 관련된 코드의 중복이 많아질텐데 그때는 Spring에서 제공하는 Pageable 객체를 사용하는 방법을 선택할 것 같아요. 페이징 처리 하는 방법을 알았으니 이제 데이터를 잘 가져오는 일만 남았는데요. 저는 이제 입출금 내역을 조회하는 API 를 만들러 떠납니다. 이 과정에서 생긴 고민 거리들도 공유해보도록 할게요!","link":"/2024/09/11/OpenAPI-Generator%EB%A1%9C-%ED%8E%98%EC%9D%B4%EC%A7%95-%EC%B2%98%EB%A6%AC%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%ED%95%B4/"},{"title":"Nginx 로 스프링 부트 8080번으로 포트포워딩 하기","text":"들어가며 도메인을 구입하고 ec2 인스턴스와 연결을 시켜주었기 때문에 IP주소가 아닌 도메인 주소로 스탠스 서비스에 접속할 수 있게 됐어요. 그런데 해당 서비스에 접속하려면 8080 포트 번호를 써줘야만 해요. 스프링 부트의 내장 웹 서버인 톰캣은 기본적으로 8080 포트이기 때문에 스프링 부트 프로젝트는 8080 포트에서 동작해요. 포트 번호를 생략하면 해당 서비스와 연결이 되지 않아요. ‘사이트에 연결할 수 없음’ 이라는 메세지만 볼 수 있을 뿐입니다. team-stance.com 의 80번지와 8080번지는 다른 주소이기 때문이죠! 그래서 포트 포워딩을 해보려고 하는데요. 특정 포트 번호에 대한 요청을 8080 포트 번호로 전달해 줄 거예요. SSL 인증서를 발급받아 프로젝트에 HTTPS 를 적용하는 과정에서 많은 시행 착오를 겪었습니다… 🥲 이 글에서는 Nginx 로 443 포트의 요청을 8080 포트에서 실행 중인 스프링 부트로 전달하는 과정에서 발생한 이슈를 공유하고자 합니다. 1. Nginx 를 설치하고 Nginx 의 응답을 확인하자ec2 인스턴스의 운영체제가 Amazon Linux 라 명령어는 해당 운영체제 기준으로 설명 드리겠습니다. 1.1. Nginx 설치ec2에 ssh 접속을 한 후 아래 명령어로 Nginx 를 설치합니다. 1sudo yum install -y nginx 1.2. Nginx 상태 확인아래의 명령어로 Nginx의 상태를 확인해봅니다. 1systemctl status nginx 123○ nginx.service - The nginx HTTP and reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; disabled; preset: disabled) Active: inactive (dead) Active: inactive (dead) 는 Nginx 가 실행되고 있지 않다는 뜻이에요. Nginx가 응답하지 않는 상태이므로 Nginx를 시작해야겠죠? 1.3. Nginx 실행1sudo systemctl start nginx 1systemctl status nginx Nginx 를 실행한 후 다시 상태를 확인해 봅시다. 아래와 같은 결과가 나온다면 Nginx 가 정상적으로 실행되고 있다는 뜻이에요. 12345678910● nginx.service - The nginx HTTP and reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; preset: disabled) Active: active (running) since Sat 2024-10-06 14:52:03 UTC; 1h 10min ago Main PID: 12345 (nginx) Tasks: 2 (limit: 1153) Memory: 1.5M CGroup: /system.slice/nginx.service ├─12345 nginx: master process /usr/sbin/nginx └─12346 nginx: worker process 1.4. Nginx 서버의 설정 파일 확인아래의 명령어로 Nginx 서버의 설정 파일에 오류가 있는지 확인해봅니다. 1nginx -t 설정 파일에 오류가 없으면 아래와 같은 메시지가 출력돼요. 12nginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful 1.4.1. Nginx 의 설정 파일을 왜 확인하나요?설정 파일에 오류가 있는 경우 Nginx를 시작하거나 재시작할 때 서버가 제대로 실행되지 않을 수 있기 때문에 nginx -t 명령어를 사용해서 사전에 문제를 확인합니다. 해당 명령어를 사용해서 설정 파일을 확인하고 수정한 후 문제가 없다면 Nginx를 안전하게 재시작하거나 로드할 수 있습니다. 1.5. 외부에서 접속했을 때 Nginx 에 연결이 되는지 확인 짜잔! HTTP 포트인 80번으로 접속했더니 Nginx 에 연결이 됐습니다. 80번 포트는 생략이 가능합니다!team-stance.com 으로 접속을 했더니 Nginx 가 응답을 하고 있네요. 2. Nginx 가 뭔데 저게 나와?80번 포트로 요청이 들어오면 Nginx 가 응답하도록 하는 설정을 한 적도 없는데 어떻게 Nginx 에서 요청을 수신하고 있는 걸까요? Nginx 는 기본적으로 설치 됐을 때 80번 포트에서 요청을 수신하도록 설정되어 있습니다. Nginx 의 기본 설정 파일에 해당 내용이 포함되어 있기 때문에 따로 설정하지 않아도 Nginx가 HTTP의 기본 포트인 80번에서 자동으로 요청을 받게 돼요. 2.1. Nginx 설정 파일 확인해 보기Nginx 를 설치하면 /etc/nginx/nginx.conf 에 파일이 생성됩니다. 이곳에 80번 포트에 대한 설정이 포함되어 있어요. ec2 인스턴스의 루트 디렉터리로 이동을 한 후 해당 경로를 찾아가 아래의 명령어를 이용해 nginx.conf 파일을 열어봅시다. 1vim nginx.conf 1234567891011121314151617server { listen 80; listen [::]:80; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; error_page 404 /404.html; location = /404.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { }} 설정 파일을 확인해 보면 위와 같을 거예요. listen 80: Nginx 가 80번 포트를 수신하도록 설정 root /usr/share/nginx/html : 해당 디렉터리에 있는 정적 파일, index.html 을 응답 80 포트로 요청했을 때 왜 “Welcome to nginx!” 페이지가 나왔는지 알게 되었습니다. 이제 HTTPS 를 적용 시켜보겠습니다. 3. Let’s Encrypt 에서 인증서 발급받기무료 SSL 인증서를 발급해주는 인증 기관인 Let’s Encrypt 를 통해서 인증서를 발급 받아보도록 하겠습니다.Let’s Encrypt 에서는 Certbot 이라는 클라이언트 도구를 사용하는 것을 추천해주고 있어서 Certbot을 설치하고 SSL 인증서를 발급 받도록 하겠습니다. 3.1. Certbot 이 뭔데?Certbot 은 Let’s Encrypt 인증서를 자동으로 요청하고 설치하기 위해 설계된 클라이언트 도구입니다. Certbot 가 하는 일은 다음과 같아요. 인증서 요청Certbot 은 Let’s Encrypt 에 요청을 보내서 도메인에 대한 SSL 인증서를 발급 받습니다. 인증서 설치인증서가 발급된 후 Certbot 은 웹 서버(Nginx, Apache)에 인증서를 자동으로 설치합니다. 갱신 자동화Let’s Encrypt 인증서는 90일 동안 유효하기 때문에 90일마다 인증서를 갱신해야 하는데, Certbot 은 자동으로 인증서를 갱신하도록 설정할 수 있습니다. 3.2. Certbot 직접 설치⭐️ Amazon Linux 2023 을 기준으로 설명합니다! Amazon Linux 2023에서는 snapd가 기본적으로 지원되지 않기 때문에 다른 방법으로 Certbot을 설치해야 합니다. Amazon Linux 2023에서는 epel-release 도 설치되지 않기 때문에 EPEL(Extra Packages for Enterprise Linux) 리포지터리를 설치하지 않고 Certbot 을 직접 설치해야 합니다. 아래의 명령어로 Certbot 을 직접 다운로드해서 사용하겠습니다. 1234sudo dnf install -y augeas-libssudo python3 -m venv /opt/certbot/sudo /opt/certbot/bin/pip install --upgrade pipsudo /opt/certbot/bin/pip install certbot 3.3. Nginx 플러그인 설치Nginx 플러그인은 Certbot의 기능 중 하나로, Nginx 설정을 자동으로 업데이트하여 SSL 인증서를 쉽게 설치할 수 있도록 도와줍니다. 3.3.1. 필요한 패키지 설치Nginx 플러그인을 사용하기 위해서는 python3-certbot-nginx 패키지를 설치해야 합니다. 아래의 명령어로 패키지를 설치합니다. 1sudo /opt/certbot/bin/pip install certbot-nginx 3.3.2. 설치 확인설치가 완료된 후 해당 명령어를 입력하면 Nginx 플러그인이 설치 되었는지 확인 할 수 있습니다. 1sudo /opt/certbot/bin/certbot plugins 설치가 되었다면 아래와 같이 Nginx 플러그인이 목록에 나타납니다. 1234567891011121314151617181920212223242526272829Saving debug log to /var/log/letsencrypt/letsencrypt.log- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -* nginxDescription: Nginx Web Server pluginInterfaces: Authenticator, Installer, PluginEntry point: EntryPoint(name='nginx',value='certbot_nginx._internal.configurator:NginxConfigurator',group='certbot.plugins')* standaloneDescription: Runs an HTTP server locally which serves the necessary validationfiles under the /.well-known/acme-challenge/ request path. Suitable if there isno HTTP server already running. HTTP challenge only (wildcards not supported).Interfaces: Authenticator, PluginEntry point: EntryPoint(name='standalone',value='certbot._internal.plugins.standalone:Authenticator',group='certbot.plugins')* webrootDescription: Saves the necessary validation files to a.well-known/acme-challenge/ directory within the nominated webroot path. Aseperate HTTP server must be running and serving files from the webroot path.HTTP challenge only (wildcards not supported).Interfaces: Authenticator, PluginEntry point: EntryPoint(name='webroot',value='certbot._internal.plugins.webroot:Authenticator',group='certbot.plugins')- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 3.4. Let’s Encrypt 인증서 발급 받기아래 명령어를 실행하여 SSL 인증서를 발급 받아 봅시다. 1sudo /opt/certbot/bin/certbot --nginx 이메일 주소를 입력하구요. 12Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): Let’s Encrypt 서비스 계약 조건에 동의도 합니다. 123Please read the Terms of Service athttps://letsencrypt.org/documents/LE-SA-v1.4-April-3-2024.pdf. You must agree inorder to register with the ACME server. Do you agree? Certbot 이 Let’s Encrypt 프로젝트와 관련된 전자 프런티어 재단(EFF)에 이메일 주소를 공유할 것인지에 대한 질문인데요. 동의 혹은 거부를 하고 넘어갑니다. 12345Would you be willing, once your first certificate is successfully issued, toshare your email address with the Electronic Frontier Foundation, a foundingpartner of the Let's Encrypt project and the non-profit organization thatdevelops Certbot? We'd like to send you email about our work encrypting the web,EFF news, campaigns, and ways to support digital freedom. Let’s Encrypt SSL 인증서를 발급받기 위해서는 다음 두 가지 도메인을 모두 입력해야 합니다: team-stance.com (루트 도메인) www.team-stance.com (서브 도메인) 12Please enter the domain name(s) you would like on your certificate (comma and/orspace separated) (Enter 'c' to cancel): team-stance.com,www.team-stance.com 여기까지 아무 문제없이 잘 오셨다면 인증서 발급이 무사히 완료될 거예요. 인증서가 발급되면 Certbot 이 443 에 대한 요청을 8080 으로 전달하는 Nginx 의 설정을 자동으로 해주기 때문에 별도로 설정 파일을 수정할 필요는 없습니다. 👇🏻 혹시나 실패 하셨다면 아래의 글을 참조해주세요. 3.4.1. [실패] A 레코드를 찾을 수 없습니다 💡 성공하신 분은 해당 챕터는 스킵하시면 됩니다. Let’s Encrypt가 도메인 team-stance.com 에 대한 A 레코드를 찾을 수 없다는 의미입니다. DNS 레코드를 확인해 볼까요? A 레코드 추가하기저는 가비아에서 도메인을 구매했기 때문에 가비아의 DNS 관리 패널에 접속해서 확인해보겠습니다. 호스트가 www 인 A 레코드가 하나밖에 없어서 아래와 같이 A 레코드를 추가해주었습니다. 값/위치 에는 인스턴스의 ip를 입력하시면 됩니다. DNS 전파 상태 확인레코드를 추가한 후 DNS 전파 상태를 확인하기 위해 WhatsMyDNS 에 접속해 확인해보겠습니다. 잘 나오는 것을 확인했으니 다시 SSL 인증서를 발급 받아 봅니다. 1sudo /opt/certbot/bin/certbot --nginx 3.4.2. [실패] 인증서는 성공적으로 발급 그러나 Nginx 에는… 인증서는 성공적으로 발급되었지만… Nginx 에는 자동으로 설치가 되지 않았다는 의미입니다. Nginx 설정 파일을 확인해 봐야 합니다. Nginx 설정 파일 수정하기Nginx 설정 파일은 루트 디렉터리를 기준으로 일반적으로 /etc/nginx/nginx.conf 또는 /etc/nginx/conf.d/ 디렉터리 내의 파일에 있습니다. 아래의 선택1과 2 중에 택하시면 됩니다. 선택1. nginx.conf 파일 수정이 파일은 Nginx 의 기본 설정을 포함하고 있기 때문에 파일을 수정하면서 잘못된 설정을 할 경우 Nginx 가 제대로 작동하지 않을 가능성이 있습니다. 선택2. conf.d 디렉터리 사용conf.d 디렉터리 내부에 새로운 .conf 파일을 생성해서 관리하면 Nginx 의 기본 설정과 분리할 수 있습니다. 그렇기 때문에 저는 해당 디렉터리에 team-stance.com.conf 파일을 생성해서 사용했습니다. 아래의 명령어를 입력하여 설정 파일을 추가해 봅시다. 1sudo vim /etc/nginx/conf.d/team-stance.com.conf 서버 블록을 추가합니다. 해당 설정을 추가하면 HTTPS 요청에 대한 처리를 할 수 있습니다. 123456789101112131415server { listen 443 ssl; server_name team-stance.com www.team-stance.com; ssl_certificate /etc/letsencrypt/sample.pem # Let's Encrypt 인증서 경로를 적어주세요. ssl_certificate_key /etc/letsencrypt/sampleKey.pem # 비공개 키 경로를 적어주세요. location / { proxy_pass http://localhost:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; }} 파일 저장 및 Nginx 재시작1sudo systemctl restart nginx 4. HTTPS 설정 확인 흑 😭 드디어 성공입니다. 인증서가 발급되고 Nginx 설정이 완료되면 Certbot 은 자동으로 Nginx 를 재시작 합니다. 브라우저에서 https://team-stance.com 와https://www.team-stance.com 으로 접속해 보면 SSL이 적용된 것을 확인 할 수 있습니다! 5. SSL 인증서 갱신 자동화Let’s Encrypt 인증서를 90일마다 갱신 해줘야 하기 때문에 Certbot 을 사용해서 자동으로 갱신하도록 설정해보겠습니다. 5.1. SSL 인증서 갱신 프로세스 시뮬레이션 하기먼저 인증서를 갱신하기 전에 모든 것이 제대로 작동하는지 테스트 하기 위해 아래의 명령어로 시뮬레이션을 실행합니다. 1sudo /opt/certbot/bin/certbot renew --dry-run 시뮬레이션을 성공적으로 마치면 아래와 같은 내용을 확인할 수 있어요! 123456Simulating renewal of an existing certificate for team-stance.com and www.team-stance.com- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Congratulations, all simulated renewals succeeded: /etc/letsencrypt/sample.pem (success)- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 5.2. 인증서 자동 갱신 코드 추가하기5.2.1. 혹시 crontab 명령어가 설치 되어 있지 않으시다면?네… 이런 오류가 발생하게 됩니다. 1sudo: crontab: command not found crontab 명령어가 설치되어 있는지부터 확인해봐야겠죠? 아래의 명령어를 입력하여 경로가 반환되는지 확인합니다. 경로가 반환되지 않는다면 우선 crontab 부터 설치해야 해요. 1which crontab crontab 설치 후 활성화아래의 명령어로 cronie 패키지를 설치하면 crontab 을 사용할 수 있습니다. 1sudo dnf install cronie 패키지를 설치한 후 cron 서비스를 시작하는 명령어를 입력합니다. 12sudo systemctl start crondsudo systemctl enable crond 아래의 명령어를 사용해서 Crontab 에 코드를 추가합니다. 1sudo crontab -e crontab 편집기에 크론 작업을 추가합니다. 저는 인증서를 매주 금요일 0시 0분에 갱신하도록 설정했어요. 10 0 * * 5 /opt/certbot/bin/certbot renew --quiet 5.3. 크론 작업 목록 확인다음 명령어를 사용해서 crontab 에 추가한 작업이 제대로 등록 되었는지 확인합니다. 1sudo crontab -l 마무리하며포트포워딩 하는 과정에서 안되는 게 많아서 너무 어렵게 느껴졌습니다. 계속 에러는 나고 이건 또 무슨 에러인지 알아보고 하나씩 해결해 나가는 과정을 겪으면서 왜 Nginx 가 필요한지 그래서 Nginx 에서 어떤 일이 일어나는지 이해할 수 있었어요. 클라이언트의 요청이 들어오면 Nginx 가 이 요청을 수신해 8080 으로 전달해준다는 큰 흐름을 머릿속에 넣고나니 어떤 걸 먼저 해야하는지 헷갈리지 않게 됐어요. 포트포워딩이 한 번에 되지 않고 여러 어려움을 겪은 덕에 머릿속에 개념이 더 확실히 잡혔습니다. 오히려 좋아! 저와 같은 에러를 겪고 계신 분들에게 이 글이 도움이 되었으면 좋겠습니다.","link":"/2024/10/07/Nginx%EB%A1%9C-%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8-8080%EB%B2%88%EC%9C%BC%EB%A1%9C-%ED%8F%AC%ED%8A%B8-%ED%8F%AC%EC%9B%8C%EB%94%A9-%ED%95%98%EA%B8%B0/"}],"tags":[{"name":"RESTful-API","slug":"RESTful-API","link":"/tags/RESTful-API/"},{"name":"GitHub_Pages","slug":"GitHub-Pages","link":"/tags/GitHub-Pages/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"order-by","slug":"order-by","link":"/tags/order-by/"},{"name":"group-by","slug":"group-by","link":"/tags/group-by/"},{"name":"rank","slug":"rank","link":"/tags/rank/"},{"name":"partition-by","slug":"partition-by","link":"/tags/partition-by/"},{"name":"OpenAPI-Generator","slug":"OpenAPI-Generator","link":"/tags/OpenAPI-Generator/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"포트포워딩","slug":"포트포워딩","link":"/tags/%ED%8F%AC%ED%8A%B8%ED%8F%AC%EC%9B%8C%EB%94%A9/"}],"categories":[{"name":"소프트웨어 아키텍처","slug":"소프트웨어-아키텍처","link":"/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"데이터베이스","slug":"데이터베이스","link":"/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4/"},{"name":"인프라","slug":"인프라","link":"/categories/%EC%9D%B8%ED%94%84%EB%9D%BC/"}],"pages":[]}